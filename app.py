import streamlit as st
import pandas as pd
import subprocess
import os
import time
from datetime import datetime
import pypianoroll
import matplotlib.pyplot as plt
from midi2audio import FluidSynth
from miditoolkit import MidiFile
from pydub import AudioSegment  # è¿½åŠ 
from pydub.effects import normalize  # è¿½åŠ 

# ==========================================
# è¨­å®šãƒ»å®šæ•°
# ==========================================
# å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜å…ˆ
DATA_LOG_FILE = "experiment1_results.csv"

# ã‚µã‚¦ãƒ³ãƒ‰ãƒ•ã‚©ãƒ³ãƒˆã®ãƒ‘ã‚¹ (ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå†…ã®ãƒ‘ã‚¹ã«åˆã‚ã›ã¦ãã ã•ã„)
SOUND_FONT_PATH = "EMO-Disentanger/SalamanderGrandPiano-SF2-V3+20200602/SalamanderGrandPiano-V3+20200602.sf2"

# ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
TEMP_DIR = "experiment_temp"
os.makedirs(TEMP_DIR, exist_ok=True)

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="EMO-Music è©•ä¾¡å®Ÿé¨“",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ==========================================
# é–¢æ•°å®šç¾©
# ==========================================

def convert_midi_to_wav(midi_path, wav_path):
    """
    MIDIã‚’WAVã«å¤‰æ›ã—ã€éŸ³é‡ã‚’ãƒãƒ¼ãƒãƒ©ã‚¤ã‚ºï¼ˆæœ€å¤§åŒ–ï¼‰ã™ã‚‹ã€‚
    1. Channel 9 ãªã©ã®éŸ³è‰²ä¸æ•´åˆã‚’ä¿®æ­£
    2. FluidSynth ã§ WAV åŒ–
    3. pydub ã§éŸ³é‡ã‚’ãƒ–ãƒ¼ã‚¹ãƒˆ (Normalize)
    """
    try:
        # --- Step 1: MIDIãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿®æ­£ (éŸ³è‰²å‰²ã‚Šå½“ã¦) ---
        midi_obj = MidiFile(midi_path)
        
        for instrument in midi_obj.instruments:
            # å¼·åˆ¶çš„ã«ãƒ”ã‚¢ãƒ(Program 0)ã«è¨­å®šã—ã€ãƒ‰ãƒ©ãƒ ãƒ•ãƒ©ã‚°ã‚’æŠ˜ã‚‹
            instrument.program = 0
            instrument.is_drum = False
        
        # ä¿®æ­£ã—ãŸMIDIã‚’ä¸€æ™‚ä¿å­˜
        fixed_midi_path = midi_path.replace(".mid", "_fixed.mid")
        midi_obj.dump(fixed_midi_path)
        
        # --- Step 2: WAVå¤‰æ› (FluidSynth) ---
        fs = FluidSynth(SOUND_FONT_PATH)
        fs.midi_to_audio(fixed_midi_path, wav_path)
        
        # --- Step 3: éŸ³é‡ãƒãƒ¼ãƒãƒ©ã‚¤ã‚º (pydub) ---
        # ç”Ÿæˆã•ã‚ŒãŸWAVã‚’èª­ã¿è¾¼ã‚€
        audio = AudioSegment.from_wav(wav_path)
        
        # ãƒãƒ¼ãƒãƒ©ã‚¤ã‚ºï¼ˆãƒ”ãƒ¼ã‚¯ã‚’ 0dBFS ã«åˆã‚ã›ã‚‹ï¼éŸ³å‰²ã‚Œã—ãªã„æœ€å¤§éŸ³é‡ã«ã™ã‚‹ï¼‰
        normalized_audio = normalize(audio)
        
        # ã•ã‚‰ã«å°‘ã—ãƒ–ãƒ¼ã‚¹ãƒˆã—ãŸã„å ´åˆã¯ä»¥ä¸‹ã®ã‚ˆã†ã«ã‚²ã‚¤ãƒ³ã‚’è¿½åŠ ï¼ˆãŠå¥½ã¿ã§ï¼‰
        # normalized_audio = normalized_audio + 3  # +3dB
        
        # ä¸Šæ›¸ãä¿å­˜
        normalized_audio.export(wav_path, format="wav")
        
        return True
    except Exception as e:
        st.error(f"WAVå¤‰æ›/éŸ³é‡èª¿æ•´ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def visualize_pianoroll(midi_path):
    """MIDIã‚’ãƒ”ã‚¢ãƒãƒ­ãƒ¼ãƒ«ã¨ã—ã¦è¡¨ç¤ºã™ã‚‹"""
    try:
        multitrack = pypianoroll.read(midi_path)
        if len(multitrack.tracks) > 0:
            fig, ax = plt.subplots(figsize=(10, 3))
            pypianoroll.plot_track(multitrack.tracks, ax=ax)
            st.pyplot(fig)
        else:
            st.warning("MIDIãƒˆãƒ©ãƒƒã‚¯ãŒç©ºã§ã™")
    except Exception as e:
        st.error(f"å¯è¦–åŒ–ã‚¨ãƒ©ãƒ¼: {e}")

def run_generation(midi_file_path, emotion_label):
    """run_pipeline.sh ã‚’å®Ÿè¡Œã™ã‚‹"""
    cmd = ["bash", "run_pipeline.sh", midi_file_path, emotion_label]
    
    try:
        result = subprocess.run(cmd, capture_output=True, text=True)
        if result.returncode!= 0:
            st.error("ç”Ÿæˆã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
            st.code(result.stderr)
            return None
        
        basename = os.path.splitext(os.path.basename(midi_file_path))
        output_dir = "EMO-Disentanger/generation/pipeline_output"
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åãƒ‘ã‚¿ãƒ¼ãƒ³æ§‹ç¯‰
        target_file_name = f"harm_{basename}_{emotion_label}_full.mid"
        target_path = os.path.join(output_dir, target_file_name)
        
        if os.path.exists(target_path):
            return target_path
        else:
            st.warning(f"æŒ‡å®šãƒ•ã‚¡ã‚¤ãƒ« {target_file_name} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚æœ€æ–°ã®ç”Ÿæˆç‰©ã‚’æ¢ç´¢ã—ã¾ã™ã€‚")
            if not os.path.exists(output_dir):
                 return None
            files = [os.path.join(output_dir, f) for f in os.listdir(output_dir) if f.endswith(".mid")]
            if not files:
                return None
            latest_file = max(files, key=os.path.getctime)
            return latest_file

    except Exception as e:
        st.error(f"å®Ÿè¡Œæ™‚ä¾‹å¤–: {e}")
        return None

def save_evaluation(user_id, input_filename, emotion, ratings, feedback):
    """è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã‚’CSVã«è¿½è¨˜ä¿å­˜"""
    data = {
        "timestamp": [datetime.now()],
        "user_id": [user_id],
        "input_midi": [input_filename],
        "emotion_condition": [emotion],
        "score_emotion_match": [ratings["emotion"]],
        "score_consistency": [ratings["consistency"]],
        "score_control": [ratings["control"]],
        "score_usefulness": [ratings["usefulness"]],
        "feedback": [feedback]
    }
    df = pd.DataFrame(data)
    
    if not os.path.isfile(DATA_LOG_FILE):
        df.to_csv(DATA_LOG_FILE, index=False)
    else:
        df.to_csv(DATA_LOG_FILE, mode='a', header=False, index=False)

# ==========================================
# ãƒ¡ã‚¤ãƒ³ UI
# ==========================================

st.title("ğŸ¹ EMO-Music ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ è©•ä¾¡å®Ÿé¨“")
st.markdown("""
ã“ã®å®Ÿé¨“ã§ã¯ã€ã‚ãªãŸãŒå…¥åŠ›ã—ãŸãƒ¡ãƒ­ãƒ‡ã‚£ã«å¯¾ã—ã¦ã€AIãŒç‰¹å®šã®**æ„Ÿæƒ… (Emotion)** ã«åˆã‚ã›ãŸä¼´å¥ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
ç”Ÿæˆã•ã‚ŒãŸæ¥½æ›²ã‚’è´ãã€ãã®å“è³ªã‚„ã‚·ã‚¹ãƒ†ãƒ ã®æœ‰ç”¨æ€§ã‚’è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚
""")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼: ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±
with st.sidebar:
    st.header("å®Ÿé¨“è€…æƒ…å ±")
    user_id = st.text_input("ãƒ¦ãƒ¼ã‚¶ãƒ¼ID (æ°åã¾ãŸã¯è­˜åˆ¥å­)", value="guest")
    st.info("â€»IDã‚’å…¥åŠ›ã—ãªã„ã¨çµæœã‚’ä¿å­˜ã§ãã¾ã›ã‚“")

# --- Step 1: ãƒ¡ãƒ­ãƒ‡ã‚£å…¥åŠ› ---
st.header("Step 1: ãƒ¡ãƒ­ãƒ‡ã‚£ã®å…¥åŠ›")
st.markdown("8å°ç¯€ç¨‹åº¦ã®çŸ­ã„ãƒ¡ãƒ­ãƒ‡ã‚£ï¼ˆMIDIãƒ•ã‚¡ã‚¤ãƒ«ï¼‰ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")

uploaded_file = st.file_uploader("MIDIãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‰ãƒ©ãƒƒã‚°ï¼†ãƒ‰ãƒ­ãƒƒãƒ—", type=["mid", "midi"])

if uploaded_file is not None:
    # ä¸€æ™‚ä¿å­˜
    temp_input_path = os.path.join(TEMP_DIR, uploaded_file.name)
    with open(temp_input_path, "wb") as f:
        f.write(uploaded_file.getbuffer())
    
    st.success(f"èª­ã¿è¾¼ã¿å®Œäº†: {uploaded_file.name}")
    
    # ãƒ”ã‚¢ãƒãƒ­ãƒ¼ãƒ«å¯è¦–åŒ–
    with st.expander("å…¥åŠ›ãƒ¡ãƒ­ãƒ‡ã‚£ã®ç¢ºèª (ãƒ”ã‚¢ãƒãƒ­ãƒ¼ãƒ«)", expanded=True):
        visualize_pianoroll(temp_input_path)

    # --- Step 2: æ„Ÿæƒ…é¸æŠ & ç”Ÿæˆ ---
    st.header("Step 2: æ„Ÿæƒ…ã®æŒ‡å®šã¨ç”Ÿæˆ")
    
    emotion_options = {
        "Q1": "Q1: å–œã³ (Joy) - æ˜ã‚‹ãã‚¨ãƒãƒ«ã‚®ãƒƒã‚·ãƒ¥",
        "Q2": "Q2: æ€’ã‚Š (Anger/Tension) - æ¿€ã—ãç·Šå¼µæ„ŸãŒã‚ã‚‹",
        "Q3": "Q3: æ‚²ã—ã¿ (Sadness) - æš—ãé™ã‹",
        "Q4": "Q4: æ¥½ã—ã„ (Happy/Relax) - æ˜ã‚‹ãè½ã¡ç€ã„ã¦ã„ã‚‹"
    }
    
    selected_emotion_key = st.radio(
        "ç”Ÿæˆã—ãŸã„æ„Ÿæƒ…ã‚’é¸ã‚“ã§ãã ã•ã„",
        list(emotion_options.keys()),
        format_func=lambda x: emotion_options[x]
    )

    if st.button("ğŸš€ ä¼´å¥ã‚’ç”Ÿæˆã™ã‚‹", type="primary"):
        if not user_id:
            st.error("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ãƒ¦ãƒ¼ã‚¶ãƒ¼IDã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        else:
            with st.status("AIãŒä½œæ›²ä¸­...", expanded=True) as status:
                st.write("1. å’Œå£°é€²è¡Œã‚’ç”Ÿæˆä¸­ (EMO_Harmonizer)...")
                # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ
                midi_output_path = run_generation(temp_input_path, selected_emotion_key)
                
                if midi_output_path:
                    st.write("2. ä¼´å¥ã‚’ç”Ÿæˆä¸­ (Stage 2)...")
                    st.write("3. éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã«å¤‰æ›ãƒ»éŸ³é‡èª¿æ•´ä¸­ (Normalization)...")
                    
                    # WAVå¤‰æ› (ä¿®æ­£æ¸ˆã¿ã®é–¢æ•°ã‚’ä½¿ç”¨)
                    wav_output_path = midi_output_path.replace(".mid", ".wav")
                    success = convert_midi_to_wav(midi_output_path, wav_output_path)
                    
                    if success:
                        status.update(label="ç”Ÿæˆå®Œäº†ï¼", state="complete", expanded=False)
                        
                        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿å­˜ã—ã¦å†æç”»å¯¾ç­–
                        st.session_state['generated_wav'] = wav_output_path
                        st.session_state['current_emotion'] = selected_emotion_key
                        st.session_state['current_midi_name'] = uploaded_file.name
                    else:
                        status.update(label="WAVå¤‰æ›ã«å¤±æ•—ã—ã¾ã—ãŸ", state="error")
                else:
                    status.update(label="ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ", state="error")

    # --- Step 3: è©•ä¾¡ãƒ•ã‚©ãƒ¼ãƒ  ---
    if 'generated_wav' in st.session_state:
        st.divider()
        st.header("Step 3: è©¦è´ã¨è©•ä¾¡")
        
        st.markdown(f"**ç”Ÿæˆã•ã‚ŒãŸæ¡ä»¶:** `{st.session_state['current_emotion']}` (å…¥åŠ›: `{st.session_state['current_midi_name']}`)")
        
        # ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼
        st.audio(st.session_state['generated_wav'], format="audio/wav")
        
        # è©•ä¾¡ãƒ•ã‚©ãƒ¼ãƒ 
        with st.form("eval_form"):
            st.subheader("ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆ")
            
            c1, c2 = st.columns(2)
            with c1:
                score_emotion = st.slider(
                    "1. æ„Ÿæƒ…ä¸€è‡´åº¦: æŒ‡å®šã—ãŸæ„Ÿæƒ…ã«åˆã£ã¦ã„ã¾ã™ã‹ï¼Ÿ",
                    1, 5, 3, help="1: å…¨ãåˆã£ã¦ã„ãªã„ ã€œ 5: éå¸¸ã«åˆã£ã¦ã„ã‚‹"
                )
                score_consistency = st.slider(
                    "2. ä¸€è²«æ€§: ãƒ¡ãƒ­ãƒ‡ã‚£ã¨ä¼´å¥ã¯é¦´æŸ“ã‚“ã§ã„ã¾ã™ã‹ï¼Ÿ",
                    1, 5, 3, help="1: é•å’Œæ„ŸãŒã‚ã‚‹ ã€œ 5: è‡ªç„¶ã§ã‚ã‚‹"
                )
            with c2:
                score_control = st.slider(
                    "3. æ“ä½œæ„Ÿ: æ„å›³é€šã‚Šã«ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ã§ããŸã¨æ„Ÿã˜ã¾ã™ã‹ï¼Ÿ",
                    1, 5, 3
                )
                score_usefulness = st.slider(
                    "4. æœ‰ç”¨æ€§: ä½œæ›²æ”¯æ´ãƒ„ãƒ¼ãƒ«ã¨ã—ã¦å½¹ã«ç«‹ã¡ãã†ã§ã™ã‹ï¼Ÿ",
                    1, 5, 3
                )
            
            feedback = st.text_area("è‡ªç”±è¨˜è¿° (æ°—ã«ãªã£ãŸç‚¹ã€æ”¹å–„ç‚¹ãªã©)")
            
            submitted = st.form_submit_button("è©•ä¾¡ã‚’é€ä¿¡ã—ã¦ãƒªã‚»ãƒƒãƒˆ")
            
            if submitted:
                save_evaluation(
                    user_id,
                    st.session_state['current_midi_name'],
                    st.session_state['current_emotion'],
                    {
                        "emotion": score_emotion,
                        "consistency": score_consistency,
                        "control": score_control,
                        "usefulness": score_usefulness
                    },
                    feedback
                )
                st.success("è©•ä¾¡ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼æ¬¡ã®æ¡ä»¶ã‚’è©¦ã—ã¦ãã ã•ã„ã€‚")
                # ã‚¹ãƒ†ãƒ¼ãƒˆã‚’ã‚¯ãƒªã‚¢ã—ã¦ãƒªã‚»ãƒƒãƒˆ
                del st.session_state['generated_wav']
                time.sleep(1)
                st.rerun()
